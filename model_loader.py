import json
from typing import Dict, Any
import numpy as np
import pandas as pd
import logging
from pathlib import Path
import pickle
import os

logger = logging.getLogger(__name__)

class ModelLoader:
    def __init__(self, model_path: str = "models/xgboost_pipeline.pkl"):
        self.model_path = Path(model_path)
        self.pipeline = None
        self.optimal_threshold = 0.5  # Seuil par d√©faut
        
    def load_model(self):
        """Charge le mod√®le avec gestion d'erreurs."""
        try:
            # V√©rifier que le fichier existe
            if not self.model_path.exists():
                raise FileNotFoundError(
                    f"‚ùå Mod√®le non trouv√© : {self.model_path}\n"
                    f"üí° Assurez-vous d'avoir ex√©cut√© 'python train_final_model.py'"
                )
            
            # Charger le mod√®le
            logger.info(f"üì• Chargement du mod√®le depuis {self.model_path}...")
            
            with open(self.model_path, 'rb') as f:
                self.pipeline = pickle.load(f)
            
            # Le fichier contient juste le pipeline (mod√®le dummy)
            # Pas de config, pas de feature_names
            
            logger.info("‚úÖ Mod√®le charg√© avec succ√®s")
            logger.info(f"üìä Seuil optimal : {self.optimal_threshold}")
            
        except FileNotFoundError as e:
            logger.error(str(e))
            raise
            
        except Exception as e:
            logger.error(f"‚ùå Erreur lors du chargement du mod√®le : {e}")
            raise RuntimeError(
                f"Impossible de charger le mod√®le depuis {self.model_path}. "
                f"Erreur : {e}"
            )
        
    def predict(self, features: Dict[str, Any]) -> Dict[str, Any]:
        """
        Faire une pr√©diction √† partir d'un dictionnaire de features
        
        Args:
            features: Dictionnaire avec les valeurs des features
            
        Returns:
            Dictionnaire avec prediction, probability, confidence
        """
        if self.pipeline is None:
            raise RuntimeError("Mod√®le non charg√©. Appelez load_model() d'abord.")
        
        # Convertir en DataFrame (1 ligne)
        df = pd.DataFrame([features])
        
        # Le mod√®le dummy accepte n'importe quelles features
        # On prend juste les valeurs num√©riques
        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
        
        if len(numeric_cols) == 0:
            # Si aucune colonne num√©rique, cr√©er des valeurs par d√©faut
            df_numeric = pd.DataFrame(np.random.rand(1, 20))
        else:
            # Prendre les colonnes num√©riques
            df_numeric = df[numeric_cols]
            
            # Si moins de 20 colonnes, compl√©ter avec des 0
            if df_numeric.shape[1] < 20:
                missing_cols = 20 - df_numeric.shape[1]
                for i in range(missing_cols):
                    df_numeric[f'feature_{i}'] = 0
        
        # Ne garder que 20 colonnes (le mod√®le dummy en attend 20)
        df_numeric = df_numeric.iloc[:, :20]
        
        try:
            # Pr√©diction (probabilit√©)
            proba = self.pipeline.predict_proba(df_numeric)[0, 1]
            
            # Pr√©diction (classe) avec seuil optimal
            prediction = "Oui" if proba >= self.optimal_threshold else "Non"
            
            # Score de confiance
            confidence = proba if prediction == "Oui" else (1 - proba)
            
            return {
                'prediction': prediction,
                'confidence_score': float(confidence)
            }
            
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de la pr√©diction : {e}")
            # Retourner une pr√©diction par d√©faut
            return {
                'prediction': 'Non',
                'confidence_score': 0.5
            }

# Instance globale
model_loader = ModelLoader()