import pickle
import json
import joblib
import pandas as pd
import numpy as np
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder
from sklearn.pipeline import Pipeline
from sklearn.model_selection import train_test_split
from xgboost import XGBClassifier

print("="*80)
print("üöÄ ENTRA√éNEMENT DU MOD√àLE XGBOOST FINAL")
print("="*80)

# =============================================================================
# 1. CHARGEMENT DES DONN√âES
# =============================================================================

print("\nüìÇ Chargement du dataset...")
with open('01_classe.pkl', 'rb') as f:
    df = pickle.load(f)

print(f"‚úÖ Dataset charg√© : {len(df)} lignes, {len(df.columns)} colonnes")

# =============================================================================
# 2. PR√âPARATION DES DONN√âES
# =============================================================================

print("\nüîß Pr√©paration des donn√©es...")

# Supprimer la colonne id_employe
df_modelisation = df.drop(columns=['id_employe'])

# Encodage de la cible
df_modelisation['d√©mission'] = df_modelisation['d√©mission'].map({'Non': 0, 'Oui': 1})

# S√©paration X et y
X = df_modelisation.drop(columns=['d√©mission'])
y = df_modelisation['d√©mission']

print(f"‚úÖ Features : {len(X.columns)} colonnes")
print(f"‚úÖ Target : {y.value_counts().to_dict()}")

# Liste des 29 features du mod√®le Light 100%
feature_names = [
    'poste', 'heure_supplementaires', 'frequence_deplacement', 'age',
    'statut_marital', 'annees_experience_totale', 'niveau_education',
    'departement', 'participation_pee', 'annees_dans_l_entreprise',
    'genre', 'annes_sous_responsable_actuel', 'satisfaction',
    'experiences_precedentes', 'domaine_etude', 'distance_domicile_travail',
    'pro_perso', 'satisfaction_equilibre_pro_perso', 'revenu_mensuel',
    'revenu_log', 'satisfaction_nature_travail', 'note_evaluation_precedente',
    'nb_formations_suivies', 'annees_depuis_la_derniere_promotion',
    'satisfaction_environnement', 'variation_evaluation', 'reconnaissance',
    'augmentation_salaire_precedent', 'satisfaction_equipe'
]

# V√©rifier que toutes les features existent
missing_features = [f for f in feature_names if f not in X.columns]
if missing_features:
    print(f"‚ö†Ô∏è  Features manquantes : {missing_features}")
    print("   On utilise toutes les features disponibles √† la place.")
    feature_names = X.columns.tolist()

X = X[feature_names]

print(f"‚úÖ Features s√©lectionn√©es : {len(feature_names)}")

# =============================================================================
# 3. PREPROCESSING
# =============================================================================

print("\nüîÑ Configuration du preprocessing...")

# Identifier les variables cat√©gorielles
variables_objects = [
    col for col in X.select_dtypes(include=["object"]).columns
]

print(f"‚úÖ Variables cat√©gorielles : {len(variables_objects)}")

# Cr√©er le preprocessor
preprocessor_cat = ColumnTransformer(
    transformers=[
        ("onehot", OneHotEncoder(handle_unknown="ignore", sparse_output=False), variables_objects),
    ],
    remainder="passthrough"
)

# =============================================================================
# 4. S√âPARATION TRAIN/TEST
# =============================================================================

print("\n‚úÇÔ∏è  S√©paration des donn√©es...")

X_train, X_test, y_train, y_test = train_test_split(
    X, y, 
    stratify=y, 
    test_size=0.2, 
    random_state=42
)

print(f"‚úÖ Train : {len(X_train)} lignes")
print(f"‚úÖ Test  : {len(X_test)} lignes")

# =============================================================================
# 5. CALCUL DU SCALE_POS_WEIGHT
# =============================================================================

scale_pos_weight = len(y_train[y_train == 0]) / len(y_train[y_train == 1])
print(f"\n‚öñÔ∏è  Scale_pos_weight : {scale_pos_weight:.2f}")

# =============================================================================
# 6. CR√âATION DU MOD√àLE XGBOOST
# =============================================================================

print("\nü§ñ Cr√©ation du mod√®le XGBoost...")

xgb_model = XGBClassifier(
    enable_categorical=True,
    random_state=42,
    n_jobs=-1,
    tree_method='hist',
    scale_pos_weight=scale_pos_weight,
    # Hyperparam√®tres optimaux
    colsample_bytree=0.8,
    learning_rate=0.05,
    max_depth=3,
    min_child_weight=5,
    n_estimators=100,
    subsample=0.8
)

# Pipeline complet
pipeline_final = Pipeline([
    ('preprocessor', preprocessor_cat),
    ('classifier', xgb_model)
])

print("‚úÖ Pipeline cr√©√©")

# =============================================================================
# 7. ENTRA√éNEMENT
# =============================================================================

print("\nüîÑ Entra√Ænement du mod√®le...")

pipeline_final.fit(X_train, y_train)

print("‚úÖ Mod√®le entra√Æn√© avec succ√®s !")

# =============================================================================
# 8. √âVALUATION RAPIDE
# =============================================================================

print("\nüìä √âvaluation rapide sur le jeu de test...")

from sklearn.metrics import classification_report, roc_auc_score

optimal_threshold = 0.090

y_proba_test = pipeline_final.predict_proba(X_test)[:, 1]
y_pred_test = (y_proba_test >= optimal_threshold).astype(int)

print(f"\n   Seuil utilis√© : {optimal_threshold}")
print("\n" + classification_report(y_test, y_pred_test, target_names=['Reste', 'D√©mission']))

roc_auc = roc_auc_score(y_test, y_proba_test)
print(f"   ROC-AUC : {roc_auc:.4f}")

# =============================================================================
# 9. SAUVEGARDE
# =============================================================================

print("\nüíæ Sauvegarde des fichiers...")

# Sauvegarder le pipeline complet
joblib.dump(pipeline_final, 'xgboost_model.pkl')
print("‚úÖ xgboost_model.pkl sauvegard√©")

# Sauvegarder le preprocessor s√©par√©ment (au cas o√π)
joblib.dump(preprocessor_cat, 'preprocessor.pkl')
print("‚úÖ preprocessor.pkl sauvegard√©")

# Sauvegarder la liste des features
joblib.dump(feature_names, 'feature_names.pkl')
print("‚úÖ feature_names.pkl sauvegard√©")

# Sauvegarder la configuration
config = {
    'optimal_threshold': optimal_threshold,
    'scale_pos_weight': scale_pos_weight,
    'n_features': len(feature_names),
    'feature_names': feature_names,
    'hyperparameters': {
        'colsample_bytree': 0.8,
        'learning_rate': 0.05,
        'max_depth': 3,
        'min_child_weight': 5,
        'n_estimators': 100,
        'subsample': 0.8
    },
    'model_type': 'XGBoost',
    'model_version': 'Light_100%',
    'f2_score': 0.6818
}

with open('model_config.json', 'w') as f:
    json.dump(config, f, indent=4)
print("‚úÖ model_config.json sauvegard√©")

# =============================================================================
# 10. R√âCAPITULATIF
# =============================================================================

print("\n" + "="*80)
print("‚úÖ ENTRA√éNEMENT TERMIN√â")
print("="*80)
print("\nüìÅ Fichiers cr√©√©s :")
print("   ‚Ä¢ xgboost_model.pkl      (Pipeline complet)")
print("   ‚Ä¢ preprocessor.pkl       (OneHotEncoder)")
print("   ‚Ä¢ feature_names.pkl      (Liste des 29 features)")
print("   ‚Ä¢ model_config.json      (Configuration et m√©tadonn√©es)")
print("\nüéØ Prochaine √©tape : Int√©grer le mod√®le dans l'API FastAPI")
print("="*80)