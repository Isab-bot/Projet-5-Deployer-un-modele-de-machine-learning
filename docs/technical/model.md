# Documentation du Mod√®le

Documentation technique compl√®te du mod√®le de pr√©diction de d√©missions.

---

## üéØ Vue d'Ensemble

**Type de mod√®le :** XGBoost Classifier  
**Objectif :** Pr√©dire si un employ√© va d√©missionner (classification binaire)  
**Version actuelle :** v1.0  
**Date d'entra√Ænement :** D√©cembre 2024  

---

## üìä Performances du Mod√®le

### M√©triques Principales

| M√©trique | Score | Interpr√©tation |
|----------|-------|----------------|
| **F2-Score** | 0.6818 | M√©trique principale (privil√©gie le Recall) |
| **Precision** | 0.8214 | 82% des pr√©dictions "d√©mission" sont correctes |
| **Recall** | 0.9474 | 95% des vraies d√©missions sont d√©tect√©es |
| **ROC-AUC** | 0.9326 | Excellent pouvoir discriminant |
| **Accuracy** | 0.9586 | 96% de pr√©dictions correctes globalement |

### Interpr√©tation Business

‚úÖ **Recall 95%** : Le mod√®le d√©tecte 95% des d√©missions r√©elles  
‚Üí Peu de faux n√©gatifs (employ√©s √† risque non d√©tect√©s)

‚úÖ **Precision 82%** : 82% des alertes sont justifi√©es  
‚Üí Quelques faux positifs (employ√©s alert√©s qui ne d√©missionnent pas)

**Compromis optimis√© pour les RH :** Mieux vaut avoir quelques fausses alertes que de manquer des d√©missions r√©elles.

---

## üîç Caract√©ristiques (Features)

### Features d'Entr√©e

| Feature | Type | Plage | Description |
|---------|------|-------|-------------|
| `satisfaction_level` | Float | 0.0 - 1.0 | Niveau de satisfaction (0=faible, 1=√©lev√©) |
| `last_evaluation` | Float | 0.0 - 1.0 | Derni√®re √©valuation de performance |
| `number_project` | Integer | 1 - 10 | Nombre de projets assign√©s |
| `average_montly_hours` | Integer | 80 - 350 | Heures mensuelles moyennes |
| `time_spend_company` | Integer | 1 - 10 | Ann√©es d'anciennet√© |
| `Work_accident` | Binary | 0 ou 1 | A eu un accident de travail |
| `promotion_last_5years` | Binary | 0 ou 1 | A √©t√© promu dans les 5 derni√®res ann√©es |
| `departement` | Categorical | 10 valeurs | D√©partement (sales, IT, support, etc.) |
| `salary` | Categorical | low/medium/high | Niveau de salaire |

### Importance des Features

**Top 5 des features les plus influentes :**

1. **satisfaction_level** (35%) - Feature la plus importante
2. **time_spend_company** (20%)
3. **average_montly_hours** (15%)
4. **last_evaluation** (12%)
5. **number_project** (8%)

---

## ‚öôÔ∏è Architecture du Mod√®le

### Algorithme : XGBoost

**XGBoost (eXtreme Gradient Boosting)** est un algorithme de boosting performant.

**Principe :**
- Ensemble d'arbres de d√©cision
- Chaque arbre corrige les erreurs du pr√©c√©dent
- Agr√©gation des pr√©dictions

**Avantages pour ce cas d'usage :**
- ‚úÖ G√®re bien les donn√©es d√©s√©quilibr√©es
- ‚úÖ Robuste aux outliers
- ‚úÖ Interpr√©table (importance des features)
- ‚úÖ Rapide en pr√©diction (< 100ms)

---

### Hyperparam√®tres

**Hyperparam√®tres optimis√©s (via Optuna) :**
```python
{
    'n_estimators': 150,
    'max_depth': 6,
    'learning_rate': 0.1,
    'subsample': 0.8,
    'colsample_bytree': 0.8,
    'min_child_weight': 1,
    'gamma': 0,
    'reg_alpha': 0.1,
    'reg_lambda': 1.0,
    'scale_pos_weight': 3.5  # Gestion d√©s√©quilibre
}
```

**Justification `scale_pos_weight` :**
- G√®re le d√©s√©quilibre des classes (plus de "Non" que de "Oui")
- Augmente le poids des exemples positifs (d√©missions)

---

## üîß Pipeline de Pr√©traitement

### √âtapes du Pipeline
```
Donn√©es brutes ‚Üí Preprocessing ‚Üí Mod√®le ‚Üí Pr√©diction
```

**1. Gestion des valeurs manquantes**
- Aucune valeur manquante dans le dataset d'entra√Ænement
- Validation stricte via Pydantic en production

**2. Encodage des variables cat√©gorielles**
- `departement` : One-Hot Encoding (10 colonnes)
- `salary` : Ordinal Encoding (low=0, medium=1, high=2)

**3. Normalisation**
- Features num√©riques : StandardScaler
- Centrage et r√©duction (moyenne=0, √©cart-type=1)

**4. √âquilibrage des classes**
- Utilisation de `scale_pos_weight` dans XGBoost
- Pas de SMOTE/undersampling pour pr√©server les donn√©es r√©elles

---

## üìà Entra√Ænement

### Dataset

**Source :** `01_classe.joblib` (2363 employ√©s historiques)

**R√©partition :**
- **Train set :** 70% (1654 employ√©s)
- **Validation set :** 15% (355 employ√©s)
- **Test set :** 15% (354 employ√©s)

**Distribution des classes :**
- **D√©missions (Oui) :** 24% (567 employ√©s)
- **R√©tention (Non) :** 76% (1796 employ√©s)

---

### Processus d'Optimisation

**M√©thode :** Recherche d'hyperparam√®tres avec Optuna

**M√©trique d'optimisation :** F2-Score  
**Raison :** Privil√©gie le Recall (d√©tecter un maximum de d√©missions)

**Nombre d'essais :** 100 combinaisons test√©es

---

## üöÄ D√©ploiement

### Format du Mod√®le

**Fichier :** `pipeline_xgboost_optimised.joblib`  
**Taille :** ~5 MB  
**Format :** Joblib (sklearn/xgboost compatible)

**Contenu :**
```python
{
    'preprocessor': ColumnTransformer,  # Preprocessing pipeline
    'model': XGBClassifier,             # Mod√®le XGBoost entra√Æn√©
    'feature_names': list,              # Noms des features
    'threshold': float                  # Seuil optimal (si applicable)
}
```

---

### Chargement en Production

**Fichier :** `model_loader.py`
```python
import joblib

# Chargement
pipeline = joblib.load('pipeline_xgboost_optimised.joblib')

# Pr√©diction
prediction = pipeline.predict(features)
proba = pipeline.predict_proba(features)
```

**Performance :**
- Chargement : ~100ms (au d√©marrage)
- Pr√©diction : < 50ms par employ√©

---

## üéØ Utilisation du Mod√®le

### Cas d'Usage

**1. Pr√©diction individuelle**
```python
employee_data = {
    "satisfaction_level": 0.38,
    "last_evaluation": 0.53,
    ...
}
prediction = model.predict([employee_data])
```

**2. Batch de pr√©dictions**
```python
employees_df = pd.DataFrame([...])  # Plusieurs employ√©s
predictions = model.predict(employees_df)
```

**3. Score de confiance**
```python
proba = model.predict_proba(employee_data)
confidence = proba[0][1]  # Probabilit√© de d√©mission
```

---

## üîÑ Maintenance et Am√©lioration

### Monitoring

**M√©triques √† suivre en production :**
- Distribution des pr√©dictions (% Oui vs Non)
- Temps de r√©ponse de l'API
- Drift des features (satisfaction moyenne, heures moyennes)

### R√©entra√Ænement

**D√©clencheurs pour r√©entra√Æner :**
- ‚úÖ Nouvelles donn√©es disponibles (d√©missions r√©elles vs pr√©dictions)
- ‚úÖ D√©gradation des performances (baisse du F2-score)
- ‚úÖ Changements organisationnels majeurs

**Fr√©quence recommand√©e :** Trimestriel

---

## üõ°Ô∏è Limites et Biais

### Limites Connues

‚ö†Ô∏è **Donn√©es historiques :** Le mod√®le apprend du pass√©, peut ne pas capter les nouvelles tendances

‚ö†Ô∏è **Features manquantes :** Pas d'info sur salaire exact, relations interpersonnelles, contexte familial

‚ö†Ô∏è **Faux positifs :** ~18% des alertes sont incorrectes (employ√©s pr√©dits d√©mission mais qui restent)

### Biais Potentiels

‚ö†Ô∏è **Biais temporel :** Entra√Æn√© sur donn√©es pass√©es, peut √™tre moins pr√©cis sur nouvelles cohortes

‚ö†Ô∏è **Biais d√©partements :** Performance peut varier selon les d√©partements (moins de donn√©es pour certains)

**Recommandation :** Combiner pr√©dictions avec jugement RH expert

---

## üìö Ressources

**Code source :**
- Entra√Ænement : `train_final_model.py`
- Chargement : `model_loader.py`
- Tests : `tests/functional/test_model_performance.py`

**Documentation externe :**
- [XGBoost Documentation](https://xgboost.readthedocs.io/)
- [Scikit-learn Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html)

---

## üîç FAQ Technique

**Q : Pourquoi F2-Score et pas F1 ?**  
**R :** F2 privil√©gie le Recall (2x plus important que Precision). Pour les RH, mieux vaut avoir quelques fausses alertes que rater des vraies d√©missions.

**Q : Le mod√®le peut-il expliquer ses pr√©dictions ?**  
**R :** Oui, via l'importance des features. Pour une pr√©diction individuelle, SHAP values pourraient √™tre ajout√©es (am√©lioration future).

**Q : Quelle est la dur√©e de vie du mod√®le ?**  
**R :** Recommand√© de r√©entra√Æner tous les 3-6 mois avec nouvelles donn√©es.

**Q : Le mod√®le g√®re-t-il les nouvelles valeurs de features ?**  
**R :** Non, il faut r√©entra√Æner si nouvelles cat√©gories (ex: nouveau d√©partement). Les valeurs num√©riques hors plage sont g√©r√©es par le StandardScaler.